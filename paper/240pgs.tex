%% LyX 1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english, 12pt]{article}
\usepackage{times}
%\usepackage{algorithm2e}
\usepackage{url}
\usepackage{bbm}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{geometry}
\geometry{verbose,letterpaper,tmargin=2cm,bmargin=2cm,lmargin=1.5cm,rmargin=1.5cm}
\usepackage{rotating}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{setspace}
\usepackage{lineno}
\usepackage{hyperref}
\usepackage{bbm}
\usepackage{makecell}

\renewcommand{\arraystretch}{1.3}

\usepackage{xr}
\externaldocument{240pgs-supp}

%\linenumbers
%\doublespacing
\onehalfspacing
%\usepackage[authoryear]{natbib}
\usepackage{natbib} \bibpunct{(}{)}{;}{author-year}{}{,}

%Pour les rajouts
\usepackage{color}
\definecolor{trustcolor}{rgb}{0,0,1}

\def \NBTRAIT {245}

\usepackage{dsfont}
\usepackage[warn]{textcomp}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{graphicx}
\graphicspath{{../figures/}}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\usepackage{algorithm} 
\usepackage{algpseudocode} 

\let\tabbeg\tabular
\let\tabend\endtabular
\renewenvironment{tabular}{\begin{adjustbox}{max width=0.9\textwidth}\tabbeg}{\tabend\end{adjustbox}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Bold symbol macro for standard LaTeX users
%\newcommand{\boldsymbol}[1]{\mbox{\boldmath $#1$}}

%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

\usepackage{babel}
\makeatother


\begin{document}


\title{Phenome-wide and ancestry-wide polygenic scores\\from the UK Biobank}
\author{Florian Priv\'e,$^{\text{1,}*}$ ...,$^{\text{2}}$ and Bjarni J. Vilhj\'almsson$^{\text{1,3}}$}

\date{~ }
\maketitle

\noindent$^{\text{\sf 1}}$National Centre for Register-Based Research, Aarhus University, Aarhus, 8210, Denmark. \\
\noindent$^{\text{\sf 3}}$Bioinformatics Research Centre, Aarhus University, Aarhus, 8000, Denmark. \\
\noindent$^\ast$To whom correspondence should be addressed.\\

\noindent Contact: \url{florian.prive.21@gmail.com}

\vspace*{4em}

\abstract{	
}

\vspace{5em}

[FEEDBACK NEEDED:]
\begin{itemize}
	\item add name + affiliation (+ funding)
	\item tell if parts are missing or should be restructured
	\item add citations when appropriate
	\item which supplementary figures are worth moving in main text?
	\item What to export and share? All correlations/estimates?
	\item Some methods/captions not clear enough?
	\item Should assess if transformation of phenotypes is really optimal/needed?
	\item Whatever other remark you have
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\section*{Introduction}

Ever larger genetic data is becoming increasingly available to researchers.
This enables deriving polygenic scores (PGS), which summarize an individual genetic components for a particular trait or disease by combining information from many genetic variants.
Polygenic scores are usually derived from summary statistics from a large meta-analysis of multiple Genome-Wide Association Studies (GWAS) and an ancestry-matched Linkage Disequilibrium (LD) reference panel \cite[]{choi2020tutorial}. 
Yet, this is not the only way to derive polygenic scores.
Indeed, polygenic scores can be directly derived from individual-level data, i.e.\ from the genetic and phenotypic information of many individuals.
Biobank datasets such as the UK Biobank now links genetic data for half a million individuals with phenotypic data for hundreds of traits and diseases \cite[]{bycroft2018uk}.
Before having access to large genetic datasets such as the UK Biobank, using a single individual-level data to derive polygenic scores was usually pointless because of the small sample sizes available.
It proved nevertheless useful for deriving PGS for traits with moderately large effects, such as autoimmune diseases \cite[]{abraham2014accurate,prive2019efficient}.
Yet, now that we have access to such large datasets, individual-level data can be used to derive competitive PGS for hundreds of phenotypes.

A major concern about PGS is that they usually transfer poorly to other ancestries, i.e.\ a PGS derived from people of European ancestry is not likely to predict as well in people of African ancestry.
Prediction in another ancestry has been shown to decay with genetic distance to the training population \cite[]{scutari2016using,wang2020theoretical} and with increasing proportion of admixture with a distant ancestry \cite[]{bitarello2020polygenic,cavazos2020inclusion}.
Here, we are also well positioned to reiterate this concern with strong evidence. 
Indeed, while the UKBB data contains genetic information for more than 450K British or European individuals, it also contains the same data for tens of thousands of individuals of non-British ancestry \cite[]{prive2020ancestry}.
These people genetically comes from a different ancestry, but they all live in the UK and had their genetic and phenotypic information derived in the same way as people of European ancestry.
This makes the UK Biobank data very well suited for comparing and evaluating predictive performance of derived PGS in diverse ancestries.

Here we apply our fast implementation of penalized regressions \cite[]{prive2019efficient} to the UK Biobank data to derive PGS for {\NBTRAIT} traits using the UK Biobank genetic and phenotypic data only.
As an alternative method, we also run LDpred2-auto \cite[]{prive2020ldpred2}, for which we directly derive the summary statistics from the individual-level data available.
We show that results about transferability of PGS derived from European ancestry to other ancestries are quite alarming. 
Indeed, overall for around 240 phenotypes, variance of the phenotypes explained by the PGS is only 64.7\% in India, 48.6\% in China, and 18\% in Nigeria compared to in individuals of UK ancestry.
We finally derive PGS by including diverse ancestries for training the polygenic scores.
While some have shown including a few thousands individuals from other ancestries might be useful in the context of finding genetic-disease association, it does not seem beneficial in the context of prediction.

[HIGHLIGHT OTHER CONCLUSIONS?]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Results}

\subsection*{Overview of methods}

We derive polygenic scores for {\NBTRAIT} phenotypes using the UK Biobank (UKBB) data \cite[]{bycroft2018uk}.
We divide this data in 8 ancestry groups following \cite{prive2020ancestry}.
We use most of people from UK ancestry to train polygenic scores based on individual-level genotypes and phenotypes, and assess prediction in the remaining individuals from the 8 ancestry groups in the test set (Table \ref{tab:size-sets}).
We use two different methods to derive polygenic scores, penalized regression and LDpred2-auto. We also report estimates for SNP heritability $h^2$ and proportion of causal variants $p$ from LDpred2-auto.
As additional analyses, we also train models using multiple ancestry groups, and we use family history to try improving predictive models.

\begin{table}[ht]
	\centering
	\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|}
		\hline
		Set & UK1 & UK2 & UK3 & Poland & Italy & Iran & India & China & Caribbean & Nigeria \\
		\hline
		Training 1 & 367,063 & 24,061 &  &  &  &  &  &  &  &  \\
		Test 1 &  &  & 20,000 & 4136 & 6660 & 1200 & 6331 & 1810 & 2484 & 3924 \\
		\hline
		Training 2 & 367,063 &  &  & 4136 & 6660 & 1200 & 6331 & 1810 &  & 3924 \\
		Test 2 &  &  & 20,000 &  &  &  &  &  & 2484 &  \\
		\hline
	\end{tabular}
	\caption{In total, 437,669 unrelated individuals are used here. 
	First analyses use UK1 + UK2 (391,124 individuals) as training set and the other groups as test sets.
	Second analyses involve multiple ancestry training and keep only the UK3 and Caribbean groups as test sets; UK2 is removed from the training so that sample size from training 2 is the same as training 1 (391,124 individuals).\label{tab:size-sets}}
\end{table}

\subsection*{Drop in prediction in other ancestries}

Figure \ref{fig:lasso-ancestry} presents the results when fitting penalized regressions using a training set composed of UK individuals and testing in 8 different ancestry groups. Averaged over around 240 phenotypes, compared to prediction performance in individuals of UK ancestry, relative predictive ability in terms of partial-$r^2$ (see Methods) is only 93.8\% in Poland, 85.6\% in Italy, 72.2\% in Iran, 64.7\% in India, 48.6\% in China, 25.2\% in the Caribbean, and 18\% in Nigeria.
Overall, relative predictive performance decreases approximately linearly with PC distance to UK (Figure \ref{fig:ratio-dist}).
As a follow-up analysis to ensure that this drop in performance in other ancestries is not due to imputation, we perform the same analysis for 83 of the continuous phenotypes using high-quality genotyped variants (see Methods) instead of the (mostly imputed) HapMap3 variants; results are highly consistent (Figure \ref{fig:lasso-ancestry-geno}).
These results are also very similar when using LDpred2-auto instead of penalized regression for training predictive models for all phenotypes (Figure \ref{fig:ldpred2-ancestry}).
A few phenotypes deviate from this global trend; of note, prediction of bilirubin concentration ranges between for 0.537 and 0.619 (partial-$r$) for all ancestries except for China for which it is 0.415 (95\% CI: 0.374 - 0.453). 
In contrast, for e.g.\ hair and skin color, predictive performance decrease quickly and prediction for both China and Nigeria is not significantly different from 0, while of 0.420 (95\% CI: 0.409 - 0.432) for ``darker hair'' [SHOULD PROBABLY VERIFY HOW I DEFINE THESE PHENOTYPES -> TRIED WITHOUT ANY TRANSFORMATION AND PREDICTION IS BETTER -> CHANGE NUMBERS? VERIFY ALL TRANSFORMATIONS?] (Figure \ref{fig:lasso-ancestry}).

%% FIGURE 1 HERE
\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{lasso-ancestry}
\caption{Partial correlation (and 95\% CI) in the UK test set and a test set from another ancestry group (each facet). Each point represents a phenotype and training has been performed with penalized regression on UK individuals (training 1 in table \ref{tab:size-sets}) and HapMap3 variants. The slope (in blue) is computed using Deming regression accounting for standard errors in both x and y.
This slope (squared) is provided in the title, which we report as the relative predictive performance compared to testing in UK.}
\label{fig:lasso-ancestry}
\end{figure}

We then investigate some of the outlier phenotypes in figure \ref{fig:lasso-ancestry}, especially the ones from blood biochemistry which have some variants with large effects.
We focus on ``total bilirubin'', ``lipoprotein A'' (lipoA) and ``apolipoprotein B'' (apoB). We perform a localized GWAS in each of the eight ancestry groups defined here, including all variants with an imputation INFO score larger than 0.3 and within a window of 500Kb from the top hit from the GWAS in the training set 1 (UK individuals and HapMap3 variants); there are approximately 30K such variants.
For bilirubin, the top hit belongs to HapMap3 variants used in the training data and explains around 30\% of the phenotypic variance (Figure \ref{fig:zoom-bilirubin}). Effects from the three top hits are fairly consistent within all ancestry groups (Figure \ref{fig:top3-bilirubin}) explaining why genetic prediction is consistent in all ancestries, except for China for which these variants are rarer (Figure \ref{fig:lasso-ancestry}).
For lipoA, results are very different; HapMap3 variants are far from being the top hits in the UK with the top HapMap3 variant explaining 5\% of phenotypic variance in UK compared to 29\% for the top hit (Figure \ref{fig:zoom-lipoA}).
Note that this top hit is more than 200Kb away from the HapMap3 top hit from UK. 
The 3 top hits for lipoA do not have very consistent effect sizes [WHAT TO CONCLUDE FROM THIS?] (Figure \ref{fig:top3-lipoA}).
Finally, for apoB, effects from the three top hits, which are not part of HapMap3 variants, are also consistent and explain up to 8.5\% of the phenotypic variance (Figures \ref{fig:zoom-apoB} \& \ref{fig:top3-apoB}).

\subsection*{Training with multiple ancestries}

Here we use all ancestry groups expect for the Caribbean for training; we remove the same number of UK individuals to keep the same training sample size as before (Table \ref{tab:size-sets}).
In figure \ref{fig:lasso-multi}, we investigate nine phenotypes: breast cancer (phecode: 174.1), prostate cancer (186), type-2 diabetes (250.2), hypertension (401), CAD (411.4), ``darker skin'', total bilirubin concentration, lipoprotein A concentration, and years of education.
We predict in the test sets from the UK and the Caribbean; overall, predictive performance are very similar when using this multi-ancestry training compared to when using only UK individuals, in both the UK and the Caribbean. When predicting lipoprotein A concentration in the Caribbean is the only time when prediction improves strongly.

[SHOULD ALSO TRY LDPRED2-AUTO? MORE PHENOTYPES?]

\subsection*{Comparison of predictive models}

Penalized regression and LDpred2-auto provides approximately similar predictive performance across all traits and ancestries considered here (Figure \ref{fig:plr-ldpred2}); there are only four pairs of phenotype-ancestry (out of nearly 2000 pairs) for which 95\% CIs for partial-$r$ from penalized regression and LDpred2 are not overlapping: ``615: Endometriosis'' in China with 0.065 (0.0074 - 0.122) vs -0.051 (-0.108 - 0.0068); ``hard falling asleep'' in UK with -0.0349 (-0.742 - 0.0045) vs 0.071 (0.031 - 0.110); height in UK with 0.634 (0.626 - 0.643) vs 0.613 (0.605 - 0.622); log-bilirubin in Nigeria with 0.546 (0.523 - 0.569) vs 0.475 (0.449 - 0.500).
For prediction in UK ancestry, penalized regression tends to provide better predictive performance than LDpred2 when prediction is easy [OTHER WORD?] (e.g.\ partial-$r$ > 0.5) and LDpred2 tends to outperform penalized regression when predicting the phenotype is more difficult (Figure \ref{fig:plr-ldpred2}).
The sparse option in LDpred2-auto also provides similar performance as LDpred2-auto without this option (Figure \ref{fig:sparse-ldpred2}).

Sparsity of resulting effects follows a very different pattern for penalized regression compared to LDpred2-auto-sparse.
Indeed, penalized regression tends not to include variants if it is uncertain that they have a non-zero effect, i.e.\ when effects are very small and prediction is difficult (Figure \ref{fig:sparsity-plr}).
In contrast, LDpred2-auto-sparse tends not to discard variants, only when $h^2$ is large enough it sets lots of effects to 0 if $p$ is small (Figure \ref{fig:sparsity-ldpred2}). 
Finally, running each penalized regression model takes between a few minutes and a few days depending on the number of non-zero effects in the resulting model (Figure \ref{fig:timings-plr}).
In contrast, LDpred2-auto should take the same computation time for all phenotypes; it completed under seven hours for most phenotypes (Figure \ref{fig:timings-ldpred2}).


\subsection*{Heritability and prediction}

Figure \ref{fig:heritability} shows that heritability estimates from LDpred2-auto is largely similar to estimates from LD score regression (LDSC, using a 3cM window), except for phenotypes with smaller proportion of causal variants $p$ for which estimates from LDSC are unreliable.
Figures \ref{fig:heritability-quant} and \ref{fig:heritability-binary} report heritability estimates from LDpred2-auto from quantitative and binary traits. 
[DESCRIBE SOME OF THEM?]
\cite{daetwyler2008accuracy} have derived the following formula for the upper bound of the predictive accuracy of polygenic scores: $r^2 = \dfrac{h^2}{1 + (1 - r^2) \frac{M_c}{N h^2}}$, where $h^2$ is the SNP heritability, $M_c = M \cdot p$ is the number of independent loci affecting a trait and $N$ is the sample size.
We verify this equation by comparing the observed partial correlation of the PGS with the solution $r$ from this equation using the estimates from LDpred2-auto as parameters (Figure \ref{fig:upper-formula}).
We then slightly modify this equation by using $M_c = M \cdot p^\alpha$; the best fit to the data is obtained for $\alpha = 0.68$ (Figure \ref{fig:power-pred-formula}) and provides analytical values for the correlation that are very close the observed ones (Figure \ref{fig:pred-formula}).

\subsection*{Using family history to improve genetic prediction}

We first replicate the analyses of \cite{hujoel2020liability} proposing the LT-FH method to estimate the genetic liability of individuals based on family history in order to improve power in GWAS.
We derive the LT-FH phenotypes for the same 12 traits for the individuals in the training set.
We then run separately a GWAS using either the case-control phenotypes or the corresponding LT-FH phenotypes.
When comparing Z-Scores obtained from the GWAS of the LT-FH phenotypes to the ones using case-control phenotypes, we report increase in power from 28\% for prostate cancer to 580\% for Alzheimer's disease (Figure \ref{fig:power-ltfh}).
This shows that the LT-FH phenotypes better capture the genetic liability of the disease compared to the case-control phenotype.

Then, we also use these LT-FH phenotypes to train penalized regressions and see if this could improve predictive performance compared to using the case-control phenotype.
We report non-significant improvements in predictive performance for breast cancer (174.1), type-2 diabetes (250.2) and coronary artery disease (411.4) when evaluating both predictive models using the case-control status of individuals in the test set (Figure \ref{fig:lasso-ltfh}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Discussion}

We show here that transferability of PGS to other populations is at least as alarming as what has been previously reported.
Indeed, compared to three previous studies \cite[]{martin2019clinical,duncan2019analysis,wang2020theoretical}, we show a relative predictive performance compared to Europeans of 
\textasciitilde18\% for Africans (vs.\ 22\%, 42\% and 24\%), 
\textasciitilde49\% for East Asians (vs.\ 50\%, 95\% and 64\%) and 
\textasciitilde65\% for South Asians (vs.\ 60\%, 62.5\% and 72\%).
We also show that predictive performance already decrease within Europe with only \textasciitilde94\% for East Europe and \textasciitilde86\% for South Europe of the performance reached within UK. 
Previous studies have shown that this reduction in performance in other ancestries is primarly due to difference in LD and allele frequencies between populations, and not so much about difference in effects / positions of causal variants \cite[]{shi2020localizing,wang2020theoretical,cavazos2020inclusion}.
[CAN WE CONCLUDE THE SAME FROM THE ZOOM PLOTS?]

We showcase two methods to build polygenic scores when large individual-level data is available. Even though LDpred2-auto is a method based on  summary statistics, it also provides good predictive performance for individual-level data compared to penalized regression.
Fitting of penalized models is relatively fast when using 1M HapMap3 variants; we have also tried fitting penalized regression using 8M variants (3 TB!); this was possible but took several days for the phenotypes we tried (data not shown) so we have not investigated this further.
To the best of our knowledge, the implementation we use is the most efficient penalized regression implementation currently available. Recently, \cite{qian2020fast} have developed snpnet, a new R package for fitting penalized regressions on large individual-level genetic data, but we have found it to be much less efficient than our package bigstatsr (Supplementary Note).
As for LDpred2, it currently cannot be run using 8M variants, but we are investigating two ways to make this possible in future work.

Here we only use the UK Biobank data to fit polygenic scores. We do show how to use family information to slightly improve prediction. Note that we are working on extending the LT-FH model to account for additional information such as time and sex differences in prevalence.
Yet, we do not use external information such as functional annotations; those could be used to improve the heritability model assumed by predictive methods in order to improve predictive performance \cite[]{zhang2020improved}.
Moreover, we do not use external summary statistics. Nevertheless, \cite{albinana2020leveraging} have shown that an efficient strategy to improve predictive ability of polygenic scores consists in combining two different polygenic scores, one derived using external summary statistics, and another one derived using individual-level data.
Therefore, the polygenic scores derived here could be combined with polygenic scores derived using external summary statistics; we will release these PGS publicly and shared them in databases such as the PGS Catalog and the Cancer-PRSweb \cite[]{fritsche2020cancer,lambert2020polygenic}.


[PROBABLY NEED TO COMPLETE DISCU. WITH WHAT? LESSONS LEARNED?]

- Better method development for prediction in other ancestries


[whereas
GWAS in African ancestry populations are not subject to this bias \cite[]{kim2018genetic,cavazos2020inclusion}.]


- small sample size is okay if small polygenicity

- better way to choose chains in LDpred2-auto?


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Methods}

\subsection*{Data}

We derive polygenic scores for {\NBTRAIT} phenotypes using the UK Biobank (UKBB) data \cite[]{bycroft2018uk}.
We read dosages data from UKBB BGEN files using function \texttt{snp\_readBGEN()} of R package bigsnpr \cite[]{prive2017efficient}.
We divide the UKBB data in 8 ancestry groups following \cite{prive2020ancestry}, and restrict to 437,669 individuals without second-degree relatives (KING kinship $< 2^{-3.5}$).
For the variants, we use 1,040,096 HapMap3 variants used in the LD reference provided in \cite{prive2020ldpred2} and that were also present in the iPSYCH2015 data \cite[]{bybjerg2020ipsych2015} with imputation INFO score larger than 0.6.
Even though the iPSYCH data is not used in this study, we plan to use the PGS derived here for iPSYCH in the future.

To define phenotypes, we first map ICD10 and ICD9 codes (UKBB fields 40001, 40002, 40006, 40013, 41202, 41270 and 41271) to phecodes using R package PheWAS \cite[]{carroll2014r,wu2019mapping}. 
We filter down to 142 phecodes of interest that showed potential genetic signals in the PheWeb results from the SAIGE UKBB GWAS \cite[]{zhou2018efficiently,taliun2020exploring}. There are 104 phecodes for which we can predict something using penalized regression [STILL NEED TO FILTER SOME AND CHANGE NUMBERS].
Second, we look closely at all 2408 UKBB fields that we have access to and filter down to defining 111 continuous and 25 binary phenotypes based on manual curation.

\subsection*{Genotyped data}

For the genotyped data, we restrict to variants that have been genotyped on both chips used by the UK Biobank, that pass quality control (QC) for all batches (cf.\ \url{https://biobank.ctsu.ox.ac.uk/crystal/crystal/auxdata/ukb_snp_qc.txt}) and QC for possible mismappings \cite[]{kunert2020allele}, with a minor allele frequency (MAF) larger than 0.01 and imputation INFO score of 1.
There are 586,534 such high-quality variants, which we read from the BGEN imputed data so that there is no missing value.

\subsection*{Penalized regression}

To derive polygenic risk scores based on individual-level data from the UKBB, we use our fast implementation of penalized linear and logistic regressions from R package bigstatsr \cite[]{prive2019efficient}.
Recently, \cite{qian2020fast} have proposed another R package, snpnet, for fitting penalized regressions on large genetic data; we  provide theoretical and empirical evidence that bigstatsr is much faster than snpnet (Supplementary Note).
Our implementation allows for lasso and elastic-net penalizations; yet, for the sake of simplicity and because the UKBB data is very large, we have decided to only use the lasso penalty \cite[]{prive2019efficient}.
We recall that fitting a penalized linear regression with lasso penalty corresponds to finding the vector of effects $\beta$ that minimizes
\[L(\lambda) = \underbrace{ ||y - \left(\mu + G \beta + X \gamma\right)||_2^2 }_\text{Loss function} + \underbrace{ \lambda \|\beta\|_1 }_\text{Penalisation} ~,\]
where $\mu$ is an intercept, $G$ is the genotype matrix, $X$ is the matrix of covariates, $y$ is the (quantitative) phenotype of interest and $\lambda$ is a hyper-parameter that needs to be chosen.
We use sex (Field 22001), age (Field 21022), birth date (Fields 34 \& 52), Townsend deprivation index (Field 189) and the first 16 principal components (Field 22009, \cite{prive2020efficient}) as unpenalized covariates when fitting the lasso models.

We have extended our implementation in two ways by allowing for using different penalties for the variants (i.e.\ having $\sum_{j} \lambda_j |\beta_j|$ instead of $\lambda \|\beta\|_1$).
First, this enables us to use a different scaling for genotypes. By default, variants in $G$ are implicitly scaled. By using $\lambda_j \propto (\text{SD}_j)^{(\xi - 1)}$, this effectively scales variant $j$ by dividing it by $(\text{SD}_j)^\xi$ in our implementation.
The default is using $\xi = 1$ but we also test $\xi = 0$ (no scaling) and $\xi = 0.5$ (Pareto scaling). We introduce a new parameter \texttt{power\_scale} for which the user can provide a vector of values to test; the best value is chosen within the Cross-Model Selection and Averaging (CMSA) procedure \cite[]{prive2019efficient}.
We also introduce a second parameter, \texttt{power\_adaptive}, which can be used to put less penalizition on variants with the largest marginal effects \cite[]{zou2006adaptive}; we try 3 values here (0 the default, 0.5 and 1.5) and the best one is chosen within the CMSA procedure.

\subsection*{LDpred2-auto}

Using the individual-level data from the training set in the UK biobank, we run a linear regression GWAS using function \texttt{big\_univLinReg} of R package bigstatsr \cite[]{prive2017efficient}, accounting for the same covariates as in the penalized regression above.
As LD reference, we use the one provided in \cite{prive2020ldpred2} for European ancestry.
We use these summary statistics and this LD reference as input for LDpred2-auto.
LDpred2 assumes a point-normal mixture distribution for effect sizes, where only a proportion of causal variants $p$ contributes to the heritability $h^2$.
In LDpred2-auto, these two parameters are directly estimated from the data \cite[]{prive2020ldpred2}.
We use the \texttt{sparse} option in LDpred2-auto to also obtain a vector of effects that is potentially sparse, i.e.\ effects of some variants are exactly 0.
Also note that, as we use linear regression for all phenotypes, we use the total sample size instead of the effective sample size for binary phenotypes as input to LDpred2.
This means that heritability estimates from both LD score regression and LDpred2-auto has to be transformed to the liability scale using both the prevalence in the GWAS and in the population; this can be performed using function \texttt{coef\_to\_liab} from R package bigsnpr.
For simplicity, we assume here that the prevalence in the population is the same as the prevalence in the training set.

We also slightly modify the formulas used in \cite{prive2020ldpred2}; we have previously used 
\[\left(\text{se}(\hat{\gamma}_j)\right)^2 = \dfrac{(\boldsymbol{\breve{y}} - \hat{\gamma}_j \boldsymbol{\breve{G}_j})^T (\boldsymbol{\breve{y}} - \hat{\gamma}_j \boldsymbol{\breve{G}_j})}{(n - K - 1) ~ \boldsymbol{\breve{G}_j}^T \boldsymbol{\breve{G}_j}} \approx \dfrac{\boldsymbol{\breve{y}}^T \boldsymbol{\breve{y}}}{n ~ \boldsymbol{\breve{G}_j}^T \boldsymbol{\breve{G}_j}} \approx \dfrac{\text{var}(\boldsymbol{y})}{n ~ \text{var}(\boldsymbol{G_j})} ~,\]
where $\hat{\gamma}_j$ is the marginal effect of variant $j$, and where $\boldsymbol{\breve{y}}$ and $\boldsymbol{\breve{G}_j}$ are the vectors of phenotypes and genotypes for variant $j$ residualized from $K$ covariates, e.g.\ centering them.
The first approximation expects $\hat{\gamma}_j$ to be small, while the second approximation assumes the effects from covariates are small. 
However, we found here that some variants can have very large effects, e.g.\ one variant explains about 30\% of the variance in bilirubin log-concentration.
Then, instead we compute \[(\boldsymbol{\breve{y}} - \hat{\gamma}_j \boldsymbol{\breve{G}_j})^T (\boldsymbol{\breve{y}} - \hat{\gamma}_j \boldsymbol{\breve{G}_j}) = 
\boldsymbol{\breve{y}}^T \boldsymbol{\breve{y}} 
- 2 \hat{\gamma}_j \boldsymbol{\breve{G}_j}^T \boldsymbol{\breve{y}} 
+ \hat{\gamma}_j^2 \boldsymbol{\breve{G}_j}^T \boldsymbol{\breve{G}_j} = 
\boldsymbol{\breve{y}}^T \boldsymbol{\breve{y}} 
- \hat{\gamma}_j^2 \boldsymbol{\breve{G}_j}^T \boldsymbol{\breve{G}_j} ~,\]
which now gives (note the added term $\hat{\gamma}_j^2$)
\begin{equation}\label{eq:approx-sd-lin}
\text{sd}(\boldsymbol{G_j}) \approx \dfrac{\text{sd}(\boldsymbol{\breve{y}})}{\sqrt{n ~ \text{se}(\hat{\gamma}_j)^2 + \hat{\gamma}_j^2}} ~.
\end{equation}
Figure \ref{fig:new-formula} shows that the updated formula \eqref{eq:approx-sd-lin} is better; we now use it in the code of LDpred2, and also recommend using it for the QC procedure proposed in \cite{prive2020ldpred2}.

[ADD SOMETHING ABOUT HOW TO CHOOSE CHAINS?]


\subsection*{Performance metric}

Here we use the partial correlation as the performance metric, which is the correlation between the PGS and the phenotype after they have been both residualized using the covariates used in this paper (i.e.\ sex, age, birth date, deprivation index and 16 PCs).
To derive 95\% confidence intervals for these correlations, we use Fisher's Z-transformation.
We implement this in function \texttt{pcor} of R package bigstatsr and use it here. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\clearpage
%\vspace*{5em}

\section*{Software and code availability}

[TODO: EXPORT CODE FROM CLUSTER] 

All code used for this paper is available at \url{https://github.com/privefl/UKBB-PGS/tree/master/code}.
We have extensively used R packages bigstatsr and bigsnpr \cite[]{prive2017efficient} for analyzing large genetic data, packages from the future framework \cite[]{bengtsson2020unifying} for easy scheduling and parallelization of analyses on the HPC cluster, and packages from the tidyverse suite \cite[]{wickham2019welcome} for shaping and visualizing results.
We have also used R package deming to fit Deming regressions.

R packages bigstatsr and bigsnpr can be installed from GitHub.
A tutorial on fitting penalized regressions with R package bigstatsr is available at \url{https://privefl.github.io/bigstatsr/articles/penalized-regressions.html}.
A tutorial on running LDpred2 with R package bigsnpr is available at \url{https://privefl.github.io/bigsnpr/articles/LDpred2.html}.

\section*{Acknowledgements}

Authors thank GenomeDK and Aarhus University for providing computational resources and support that contributed to these research results.
This research has been conducted using the UK Biobank Resource under Application Number 58024.

\section*{Funding}

F.P. and B.V.\ are supported by the Danish National Research Foundation (Niels Bohr Professorship to Prof. John McGrath), and also acknowledge the Lundbeck Foundation Initiative for Integrative Psychiatric Research, iPSYCH (R248-2017-2003).

\section*{Declaration of Interests}

The authors declare no competing interests.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\bibliographystyle{natbib}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
