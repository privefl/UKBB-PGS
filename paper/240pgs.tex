%% LyX 1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english, 12pt]{article}
\usepackage{times}
%\usepackage{algorithm2e}
\usepackage{url}
\usepackage{bbm}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{geometry}
\geometry{verbose,letterpaper,tmargin=2cm,bmargin=2cm,lmargin=1.5cm,rmargin=1.5cm}
\usepackage{rotating}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{setspace}
\usepackage{lineno}
\usepackage{hyperref}
\usepackage{bbm}
\usepackage{makecell}

\renewcommand{\arraystretch}{1.3}

\usepackage{xr}
\externaldocument{240pgs-supp}

%\linenumbers
%\doublespacing
\onehalfspacing
%\usepackage[authoryear]{natbib}
\usepackage{natbib} \bibpunct{(}{)}{;}{author-year}{}{,}

%Pour les rajouts
\usepackage{color}
\definecolor{trustcolor}{rgb}{0,0,1}

\def \NBTRAIT {245}

\usepackage{dsfont}
\usepackage[warn]{textcomp}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{graphicx}
\graphicspath{{../figures/}}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\usepackage{algorithm}
\usepackage{algpseudocode}

\let\tabbeg\tabular
\let\tabend\endtabular
\renewenvironment{tabular}{\begin{adjustbox}{max width=0.9\textwidth}\tabbeg}{\tabend\end{adjustbox}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Bold symbol macro for standard LaTeX users
%\newcommand{\boldsymbol}[1]{\mbox{\boldmath $#1$}}

%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

\usepackage{babel}
\makeatother


\begin{document}


\title{High-resolution portability of {\NBTRAIT} polygenic scores\\when derived and applied in the same cohort}
\author{Florian Priv\'e,$^{\text{1,}*}$ Hugues Aschard,$^{\text{2,3}}$ Lasse Folkersen,$^{\text{4}}$ Clive Hoggart,$^{\text{5}}$ Paul O'Reilly,$^{\text{5}}$ and Bjarni J. Vilhj\'almsson$^{\text{1,6}}$}

\date{~ }
\maketitle

\noindent$^{\text{\sf 1}}$National Centre for Register-Based Research, Aarhus University, Aarhus, 8210, Denmark. \\
\noindent$^{\text{\sf 2}}$Department of Computational Biology, USR 3756 CNRS, Institut Pasteur, Paris, 75015, France. \\
\noindent$^{\text{\sf 3}}$Program in Genetic Epidemiology and Statistical Genetics, Harvard T.H. Chan School of Public Health, Boston, MA, 02115, USA. \\
\noindent$^{\text{\sf 4}}$Danish National Genome Center, Copenhagen, 2300, Denmark \\
\noindent$^{\text{\sf 5}}$Department of Genetics and Genomic Sciences, Icahn School of Medicine at Mount Sinai, New York, New York, 10029, USA \\
\noindent$^{\text{\sf 6}}$Bioinformatics Research Centre, Aarhus University, Aarhus, 8000, Denmark. \\
\noindent$^\ast$To whom correspondence should be addressed.\\

\noindent Contact: \url{florian.prive.21@gmail.com}

\vspace*{4em}

\abstract{
}

\clearpage

[FEEDBACK NEEDED:]
\begin{itemize}
	\item Verify names and affiliations
	\item tell if parts are missing or should be restructured
	\item add citations when appropriate
	\item which supplementary figures are worth moving in main text?
	\item What to export and share? All correlations/estimates?
	\item Some methods/captions not clear enough?
	\item Should assess if transformation of phenotypes is really optimal/needed?
	\item Whatever other remark you have
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\section*{Introduction}

Ever larger genetic data is becoming more readily available to researchers.
This enables researchers to derive polygenic scores (PGS), which summarize an individual genetic components for a particular trait or disease by combining information from many genetic variants.
In Human Genetics, polygenic scores are usually derived from summary statistics from a large meta-analysis of multiple Genome-Wide Association Studies (GWAS) and an ancestry-matched Linkage Disequilibrium (LD) reference panel \cite[]{choi2020tutorial}.
Yet, polygenic scores can be directly derived from individual-level data when available, i.e.\ from the genetic and phenotypic information of many individuals \cite[]{de2013whole}.
Biobank datasets such as the UK Biobank now links genetic data for half a million individuals with phenotypic data for hundreds of traits and diseases \cite[]{bycroft2018uk}.
Before having access to large genetic datasets such as the UK Biobank, using a single individual-level data to derive polygenic scores was usually pointless because of the small sample sizes available.
Individual-level data methods proved nevertheless useful for deriving PGS for traits with moderately large effects, such as autoimmune diseases \cite[]{abraham2014accurate,prive2019efficient}.
Yet, now that researchers can have access to large datasets, individual-level data may be used to derive competitive PGS for hundreds of phenotypes.

A major concern about PGS is that they usually transfer poorly to other ancestries, i.e.\ a PGS derived from people of European ancestry is not likely to predict as well in people of African ancestry.
Prediction in another ancestry has been shown to decay with genetic distance to the training population \cite[]{scutari2016using,wang2020theoretical} and with increasing proportion of admixture with a distant ancestry \cite[]{bitarello2020polygenic,cavazos2020inclusion}.
This portability issue is suspected to be primarly due to difference in LD and allele frequencies between populations, and not so much about difference in effects / positions of causal variants \cite[]{shi2020localizing,wang2020theoretical,cavazos2020inclusion}.
Individual-level data from the UK Biobank offer an opportunity to further investigate this problem of portability of PGS in a more controlled setting.
Indeed, while the UKBB data contains genetic information for more than 450K British or European individuals, it also contains the same data for tens of thousands of individuals of non-British ancestry \cite[]{bycroft2018uk}.
Of particular interest, those individuals of diverse ancestries all live in the UK and had their genetic and phenotypic information derived in the same way as people of European ancestry. 
This allows to circumvent potential confounding bias that might arise in comparative analyses from independent studies, and makes the UK Biobank data very well suited for comparing and evaluating predictive performance of derived PGS in diverse ancestries and across multiple phenotypes.

However, to be able to investigate portability of PGS to other ancestries, we must first define groups of different ancestries from the data.
Principal Component Analysis (PCA) has been widely used to correct for population structure in association studies and has been shown to mirror geography in Europe \cite[]{price2006principal,novembre2008genes}.
Due to its popularity, many methods have been developed for efficiently performing PCA \cite[]{abraham2017flashpca2,prive2020efficient} as well as appropriately projecting samples onto a reference PCA space \cite[]{zhang2020fast,prive2020efficient}, making possible to perform these analyses for ever increasing datasets in human genetics.
Naturally, PCA has also been used for ancestry inference. 
However, among all studies where we have seen PCA used for ancestry inference, we have found there was no consensus on what is the most appropriate method for inferring ancestry using PCA.
For example, there may be divergences on which distance metric to use and the number of PCs to use to compute these distances.

In this study, we examine the extent to which polygenic risk scores are transferable between ancestries. 
We first propose a simple, robust and effective method for global ancestry inference and grouping from PCA of genetic data, and use it to define 8 ancestry groups in the UK Biobank data.
We then apply a computationally efficient implementation of penalized regression \cite[]{prive2019efficient} to derive PGS for {\NBTRAIT} traits using the UK Biobank genetic and phenotypic data only.
As an alternative method, we also run LDpred2-auto \cite[]{prive2020ldpred2}, for which we directly derive the summary statistics from the individual-level data available.
We show a dramatically low portability of PGS from European ancestry to other ancestries.
Indeed, on average, the phenotypic variance explained by the PGS is only 64.7\% in India, 48.6\% in China, and 18\% in Nigeria compared to in individuals of UK ancestry.
These results are presented at a finer scale than the usual continental level, which allows us to show that prediction already drops within Europe (for East and South Europe compared to UK).
We also explore the performance of PGS trained using a mixture of European and non-European ancestry samples.
While some have shown including a few thousands individuals from other ancestries might be useful in the context of finding genetic-disease association and fine-mapping [CITATIONS?], here it does not prove beneficial for prediction when naively using all ancestries together in training.
[ADD SOMETHING ABOUT THE SET OF 8M VARIANTS?]
Finally, we compare penalized regression to LDpred2-auto, and show that summary statistics methods can be powerful when applied to individual-level data as well.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Results}

\subsection*{Overview of methods}

We derive polygenic scores for {\NBTRAIT} phenotypes using the UK Biobank (UKBB) data \cite[]{bycroft2018uk}.
We divide this data in 8 ancestry groups.
We use 391,124 individuals of UK ancestry to train polygenic scores based on individual-level genotypes and phenotypes, and assess prediction in remaining individuals from 8 ancestry groups (Table \ref{tab:size-sets}).
We use two different methods to derive polygenic scores, penalized regression and LDpred2-auto.
As additional analyses, we also train models using a mixture of multiple ancestries, and investigate other variants than the HapMap3 variants used in the main analyses.

\begin{table}[ht]
	\centering
	\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|}
		\hline
		Set & UK1 & UK2 & UK3 & Poland & Italy & Iran & India & China & Caribbean & Nigeria \\
		\hline
		Training 1 & 367,063 & 24,061 &  &  &  &  &  &  &  &  \\
		Test 1 &  &  & 20,000 & 4136 & 6660 & 1200 & 6331 & 1810 & 2484 & 3924 \\
		\hline
		Training 2 & 367,063 &  &  & 4136 & 6660 & 1200 & 6331 & 1810 &  & 3924 \\
		Test 2 &  &  & 20,000 &  &  &  &  &  & 2484 &  \\
		\hline
	\end{tabular}
	\caption{In total, 437,669 unrelated individuals are used here.
	First analyses use UK1 + UK2 (391,124 individuals) as training set and the other groups as test sets.
	Second analyses involve multiple ancestry training and keep only the UK3 and Caribbean groups as test sets; UK2 is removed from the training so that sample size from training 2 is the same as training 1 (391,124 individuals).\label{tab:size-sets}}
\end{table}

\subsection*{Ancestry grouping}

Detailed results can be found in the Supplementary Note; we recall main results here.
First, we show that (squared) Euclidean distances in the PCA space of genetic data are approximately proportional to $F_{ST}$ between populations.
We also show that using only 2 PCs, or even 4 PCs, is not enough to distinguish between some populations.
Then, we show how to use this PCA-based distance to infer ancestry in the UK Biobank and the POPRES datasets.
We propose two solutions, either relying on projection of PCs to reference populations such as from the 1000 Genomes Project, or by directly using internal data.
We show that these solutions are simple, robust and effective methods for global ancestry inference and grouping from PCA of genetic data.
Here we use the second solution, relying on PCs computed within the UK Biobank and individual information on the countries of birth, to derive the eight ancestry groups presented in table \ref{tab:size-sets}.

\subsection*{Portability of polygenic scores to other ancestries}

Figure \ref{fig:lasso-ancestry} presents the results when fitting penalized regressions using a training set composed of UK individuals and testing in 8 different ancestry groups. Averaged over around 240 phenotypes, compared to prediction performance in individuals of UK ancestry, relative predictive ability in terms of partial-$r^2$ (see Methods) is only 93.8\% in Poland, 85.6\% in Italy, 72.2\% in Iran, 64.7\% in India, 48.6\% in China, 25.2\% in the Caribbean, and 18\% in Nigeria.
As a follow-up analysis to ensure that this drop in performance in other ancestries is not due to imputation, we perform the same analysis for 83 of the continuous phenotypes using high-quality genotyped variants only (see Methods) instead of the (mostly imputed) HapMap3 variants; results are highly consistent (Figure \ref{fig:lasso-ancestry-geno}).
These results are also very similar when using LDpred2-auto instead of penalized regression for training predictive models for all phenotypes (Figure \ref{fig:ldpred2-ancestry}).
A few phenotypes deviate from this global trend, e.g.\ prediction of bilirubin concentration ranges between 0.537 and 0.619 (partial-$r$) for all ancestries except for China for which it is 0.415 (95\% CI: 0.374 - 0.453).
In contrast, for e.g.\ hair and skin color, predictive performance decrease quickly and prediction for both China and Nigeria is not significantly different from 0, while of 0.420 (95\% CI: 0.409 - 0.432) for ``darker hair'' (Figure \ref{fig:lasso-ancestry}).
Overall, relative predictive performance decreases approximately linearly with PC distance to UK (Figure \ref{fig:ratio-dist}). A similar pattern is observed when computing PCA based on more balanced ancestry groups, as recommended in \cite{prive2020efficient} (Figure \ref{fig:ratio-dist2}).

\begin{figure}[htb]
\centering
\includegraphics[width=0.9\textwidth]{lasso-ancestry}
\caption{Partial correlation (and 95\% CI) in the UK test set versus in a test set from another ancestry group (each facet). Each point represents a phenotype and training has been performed with penalized regression on UK individuals (training 1 in table \ref{tab:size-sets}) and HapMap3 variants. The slope (in blue) is computed using Deming regression accounting for standard errors in both x and y.
This slope (squared) is provided in the title, which we report as the relative predictive performance compared to testing in UK.}
\label{fig:lasso-ancestry}
\end{figure}

\begin{figure}[htb]
	\centerline{\includegraphics[width=0.8\textwidth]{ratio-dist}}
	\caption{Relative predictive performance with UK compared to PC distance with UK. PC distances are computed using Euclidean distance between geometric medians of the first 16 reported PC scores (Field 22009) of each ancestry group. Relative performance values are the ones reported in figure \ref{fig:lasso-ancestry}.}
	\label{fig:ratio-dist}
\end{figure}

\subsection*{Using more than HapMap3 variants?}

We investigate some of the outlier phenotypes in figure \ref{fig:lasso-ancestry}, especially the ones from blood biochemistry which have some variants with large effects.
We focus on ``total bilirubin'', ``lipoprotein A'' (lipoA) and ``apolipoprotein B'' (apoB). We perform a localized GWAS which includes all variants around the top hit from the GWAS in the training set 1 (UK individuals and HapMap3 variants only) in each of the eight ancestry groups defined here. More precisely, we include all variants with an imputation INFO score larger than 0.3 and within a window of 500Kb from the HapMap3 top hit; there are approximately 30K such variants for all three phenotypes.
For bilirubin, the overall top hit is an HapMap3 variants and explains around 30\% of the phenotypic variance (Figure \ref{fig:zoom-bilirubin}). Effects from the three top hits are fairly consistent within all ancestry groups (Figure \ref{fig:top3-bilirubin}) explaining why genetic prediction is consistent in all ancestries, except for China for which these variants are rarer (Figure \ref{fig:lasso-ancestry}).
For lipoA, results are very different across ancestries; HapMap3 variants are far from being the top hits for the UK individuals, where the top HapMap3 variant explains 5\% of phenotypic variance compared to 29\% for the (non-HapMap3) top hit (Figure \ref{fig:zoom-lipoA}).
Note that this top hit is more than 200Kb away from the HapMap3 top hit from UK.
The 3 top hits for lipoA do not have very consistent effect sizes across ancestries (Figure \ref{fig:top3-lipoA}).
Finally, for apoB, effects from the three top hits, which are not part of HapMap3 variants, are fairly consistent across ancestries and explain up to 8.5\% of the phenotypic variance (Figures \ref{fig:zoom-apoB} \& \ref{fig:top3-apoB}).

We then investigate using more than HapMap3 variants for training; we use more than 8M common variants (Methods) and apply LDpred2 thanks to p-value thresholding and winner's curse correction (Methods). 
Except for lipoA for which we get a large improvement in predictive accuracy compared to using HapMap3 variants only, there is no significant improvement for the other seven phenotypes analyzed here (Figure \ref{fig:ldpred2-large}). Remarkably, while the partial correlation for lipoA is about 75\% in the UK test set when using this prioritized set of variants, it is still not different from 0 when applied to the Nigeria group.
For height and BMI, estimated heritability is reduced when using this set of most significant variants, and all these variants are estimated to be causal, i.e.\ estimate of $p$ is 1 (Table \ref{tab:ldpred2-est-large}). As height and BMI are very polygenic traits ($p$ is estimated to be \textasciitilde2\% and \textasciitilde4\% respectively when using HapMap3 variants), contribution from less significant causal variants is missed due to this thresholding selection.
For the three binary phenotypes, breast cancer (phecode: 174.1), prostate cancer (185) and coronary artery disease (411.4), while heritability estimates are larger when using this set of prioritized variants (Table \ref{tab:ldpred2-est-large}), predictive accuracy seems lower than when using HapMap3 variants (Figure \ref{fig:ldpred2-large}).

\subsection*{Training with a mixture of ancestries}

Here we use all ancestry groups expect for the Caribbean for training; we remove the same number of UK individuals to keep the same training sample size as before (training 2 in table \ref{tab:size-sets}).
We recall that Caribbean people are mostly admixed between African, European and South Asian ancestries, which are all represented here in the training set 2.
In figure \ref{fig:lasso-multi}, we investigate nine phenotypes of interest, either because they are highly studied diseases or are outliers in figure \ref{fig:lasso-ancestry}: breast cancer (phecode: 174.1), prostate cancer (186), type-2 diabetes (250.2), hypertension (401), CAD (411.4), skin tone, total bilirubin concentration, lipoprotein A concentration, and years of education.
We predict in the test sets from the UK and the Caribbean; overall, predictive performance are very similar when using this multi-ancestry training compared to when using only UK individuals, in both the UK and the Caribbean. When predicting lipoprotein A concentration in the Caribbean is the only time when prediction improves strongly.

\subsection*{Comparison of predictive models}

[ALSO ADD AVERAGE R ACROSS ALL PHENOTYPES?] Penalized regression and LDpred2-auto provides approximately similar predictive performance across all traits and ancestries considered here (Figure \ref{fig:plr-ldpred2}); there are only four pairs of phenotype-ancestry (out of nearly 2000 pairs) for which 95\% CIs for partial-$r$ from penalized regression and LDpred2 are not overlapping: ``615: Endometriosis'' in China with 0.065 (0.0074 - 0.122) vs -0.051 (-0.108 - 0.0068); ``hard falling asleep'' in UK with -0.0349 (-0.742 - 0.0045) vs 0.071 (0.031 - 0.110); height in UK with 0.634 (0.626 - 0.643) vs 0.613 (0.605 - 0.622); log-bilirubin in Nigeria with 0.546 (0.523 - 0.569) vs 0.475 (0.449 - 0.500).
For prediction in UK ancestry, penalized regression tends to provide better predictive performance than LDpred2 for traits that are well predicted (e.g.\ partial-$r$ > 0.5) and LDpred2 tends to outperform penalized regression when predicting the phenotype is more difficult (Figure \ref{fig:plr-ldpred2}).

Both methods allows for fitting sparse effects, i.e.\ some resulting effects are exactly 0. Sparse models may be beneficial because they may be more easily interpreted and implemented. 
The sparse option in LDpred2-auto provides similar performance as LDpred2-auto without this option (Figure \ref{fig:sparse-ldpred2}).
Sparsity of resulting effects follows a very different pattern for penalized regression compared to LDpred2-auto-sparse.
Indeed, penalized regression tends not to include variants if it is uncertain that they have a non-zero effect, i.e.\ when effects are very small and prediction is difficult (Figure \ref{fig:sparsity-plr}).
In contrast, LDpred2-auto-sparse tends not to discard variants, only when $h^2$ is large enough it sets lots of effects to 0 if $p$ is small (Figure \ref{fig:sparsity-ldpred2}).
Finally, running each penalized regression model takes between a few minutes and a few days depending on the number of non-zero effects in the resulting model (Figure \ref{fig:timings-plr}).
In contrast, LDpred2-auto should take the same computation time for all phenotypes; it completed under seven hours for most phenotypes (Figure \ref{fig:timings-ldpred2}).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Discussion}

In this paper, we have shown a poor portability of PGS to other populations, in agreement to what has been previously reported.
Indeed, compared to three previous studies \cite[]{martin2019clinical,duncan2019analysis,wang2020theoretical}, we show a relative predictive performance compared to Europeans of
\textasciitilde18\% for Africans (vs.\ 22\%, 42\% and 24\%),
\textasciitilde49\% for East Asians (vs.\ 50\%, 95\% and 64\%) and
\textasciitilde65\% for South Asians (vs.\ 60\%, 62.5\% and 72\%).
Our results provide a significant addition to the current literature in many ways. First, we show that the portability issue is as strong even when PGS are derived and applied in the same cohort. 
Second, the presented results are averaged over {\NBTRAIT} phenotypes, which is much more than what is typically used.
Third, we provide this result at a finer scale than the usual continental level by proposing a simple, robust and effective method for grouping UKBB individuals in eight ancestry groups.
This allows us to show e.g.\ that predictive performance already decrease within Europe with only \textasciitilde94\% for East Europe and \textasciitilde86\% for South Europe of the performance reached within UK.

We showcase two methods to build polygenic scores when large individual-level data is available. Although LDpred2-auto is a method based on summary statistics, it provides good predictive performance compared to penalized regression, when applied to individual-level data.
Moreover, portability results shown here are similar when using either the individual-level penalized regression or the summary statistics based LDpred2 method.
Fitting of penalized models is relatively fast when using 1M HapMap3 variants; we have also tried fitting penalized regression using 8M variants (>3TB of data); this was possible but took several days for the phenotypes we tried (data not shown) so we have not investigated this further.
To the best of our knowledge, the implementation we use is the most efficient penalized regression implementation currently available. Recently, \cite{qian2020fast} have developed snpnet, a new R package for fitting penalized regressions on large individual-level genetic data, but we have found it to be much less efficient than our package bigstatsr (Supplementary Note).
As for LDpred2, it currently cannot be run using 8M variants, but we show a way to use a subset of 1M prioritized variants out of these 8M. 
Using this new set of variants provides a large improvement in predicting lipoprotein A concentration (lipoA), but not for the other seven phenotypes studied in this analysis.
This improvement for lipoA is not surprising given that the top HapMap3 variant explains 5\% of phenotypic variance compared to 29\% for the (non-HapMap3) top hit (Figure \ref{fig:zoom-lipoA}).

Here we only use the UK Biobank data to fit polygenic scores.
We do not use external information such as functional annotations; those could be used to improve the heritability model assumed by predictive methods in order to improve predictive performance \cite[]{zhang2020improved}.
Moreover, we do not use external summary statistics. Nevertheless, \cite{albinana2020leveraging} have shown that an efficient strategy to improve predictive ability of polygenic scores consists in combining two different polygenic scores, one derived using external summary statistics, and another one derived using individual-level data.
Therefore, the polygenic scores derived here could be combined with polygenic scores derived using external summary statistics; we will release these PGS publicly and shared them in databases such as the PGS Catalog and the Cancer-PRSweb \cite[]{fritsche2020cancer,lambert2020polygenic}.


[PROBABLY NEED TO COMPLETE DISCU. WITH WHAT?]

- add something about multi ancestry training?

- add something about using external information to provide better portability?

- Better method development for prediction in other ancestries

- GWAS in African ancestry populations are not subject to this bias \cite[]{kim2018genetic,cavazos2020inclusion} -> same for prediction?.

- small sample size is okay if small polygenicity

- better way to choose chains in LDpred2-auto?

- add limitation on transformation of phenotypes based on visual inspection


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Materials and Methods}

\subsection*{Data}

We derive polygenic scores for {\NBTRAIT} phenotypes using the UK Biobank (UKBB) data \cite[]{bycroft2018uk}.
We read dosages data from UKBB BGEN files using function \texttt{snp\_readBGEN()} of R package bigsnpr \cite[]{prive2017efficient}.
We divide the UKBB data in 8 ancestry groups (Supplementary Note), and restrict to 437,669 individuals without second-degree relatives (KING kinship $< 2^{-3.5}$).
For the variants, we use 1,040,096 HapMap3 variants used in the LD reference provided in \cite{prive2020ldpred2} and that were also present in the iPSYCH2015 data \cite[]{bybjerg2020ipsych2015} with imputation INFO score larger than 0.6.
Even though the iPSYCH data is not used in this study, we plan to use the PGS derived here for iPSYCH in the future [OR SAY IN THE DISCUSSION WHEN WE TALK ABOUT PROVIDING THE PGS TO RESEARCHERS?].

To define phenotypes, we first map ICD10 and ICD9 codes (UKBB fields 40001, 40002, 40006, 40013, 41202, 41270 and 41271) to phecodes using R package PheWAS \cite[]{carroll2014r,wu2019mapping}.
We filter down to 142 phecodes of interest that showed potential genetic signals in the PheWeb results from the SAIGE UKBB GWAS \cite[]{zhou2018efficiently,taliun2020exploring}. There are 104 phecodes for which we can predict something using penalized regression [STILL NEED TO FILTER SOME AND CHANGE NUMBERS].
Second, we look closely at all 2408 UKBB fields that we have access to and filter down to defining 111 continuous and 25 binary phenotypes based on manual curation.


\subsection*{Additional data: genotyped data}

For the genotyped data used in some follow-up analyses, we restrict to variants that have been genotyped on both chips used by the UK Biobank, that pass quality control (QC) for all batches (cf.\ \url{https://biobank.ctsu.ox.ac.uk/crystal/crystal/auxdata/ukb_snp_qc.txt}) and QC for possible mismappings \cite[]{kunert2020allele}, with a minor allele frequency (MAF) larger than 0.01 and imputation INFO score of 1.
There are 586,534 such high-quality variants, which we read from the BGEN imputed data so that there is no missing value.

\subsection*{Additional data: 8M+ variants}

We also design a larger set of imputed variants to compare against using only HapMap3 variants for prediction. We first restrict to UKBB variant with MAF > 0.01 and INFO > 0.6.
We then compile frequencies and imputation INFO scores from other datasets, iPSYCH and summary statistics for breast cancer, prostate cancer, coronary artery disease and type-1 diabetes \cite[]{bybjerg2020ipsych2015,michailidou2017association,schumacher2018association,nikpay2015comprehensive,censin2017childhood}. 
We restrict to variants with a mean INFO > 0.5 in these other datasets, and also computed the median frequency.
To exclude potential mismappings in the genotyped data \cite[]{kunert2020allele} that might have propagated to imputed data, we compare frequencies in this data to the ones in UK Biobank (Figure \ref{fig:compare-MAF}).
As we expect these potential errors to be localized around errors in the genotype data (confirmed in figure \ref{fig:diff-MAF}), we applied a moving-average smoothing to increase power to detect these errors and also reduce false positives.
This is the same method we have previously applied to PC loadings to detect long-range LD regions when computing PCA \cite[]{prive2017efficient,prive2020efficient}. 
This results in a set of 8,238,692 variants.

\subsection*{Penalized regression}

To derive polygenic risk scores based on individual-level data from the UKBB, we use our fast implementation of penalized linear and logistic regressions from R package bigstatsr \cite[]{prive2019efficient}.
We also considered the recently developed R package snpnet for fitting penalized regressions on large genetic data; however, we provide theoretical and empirical evidence that bigstatsr is much faster than snpnet (Supplementary Note).
Our implementation allows for lasso and elastic-net penalizations; yet, for the sake of simplicity and because the UKBB data is very large, we have decided to only use the lasso penalty \cite[]{prive2019efficient}.
We recall that fitting a penalized linear regression with lasso penalty corresponds to finding the vector of effects $\beta$ that minimizes
\[L(\lambda) = \underbrace{ ||y - \left(\mu + G \beta + X \gamma\right)||_2^2 }_\text{Loss function} + \underbrace{ \lambda \|\beta\|_1 }_\text{Penalisation} ~,\]
where $\mu$ is an intercept, $G$ is the genotype matrix, $X$ is the matrix of covariates, $y$ is the (quantitative) phenotype of interest and $\lambda$ is a hyper-parameter that needs to be chosen.
We use sex (Field 22001), age (Field 21022), birth date (Fields 34 \& 52), Townsend deprivation index (Field 189) and the first 16 principal components (Field 22009, \cite{prive2020efficient}) as unpenalized covariates when fitting the lasso models.

We have extended our implementation in two ways by allowing for using different penalties for the variants (i.e.\ having $\sum_{j} \lambda_j |\beta_j|$ instead of $\lambda \|\beta\|_1$).
First, this enables us to use a different scaling for genotypes. By default, variants in $G$ are implicitly scaled. By using $\lambda_j \propto (\text{SD}_j)^{(\xi - 1)}$, this effectively scales variant $j$ by dividing it by $(\text{SD}_j)^\xi$ in our implementation.
The default is using $\xi = 1$ but we also test $\xi = 0$ (no scaling) and $\xi = 0.5$ (Pareto scaling). We introduce a new parameter \texttt{power\_scale} for which the user can provide a vector of values to test; the best value is chosen within the Cross-Model Selection and Averaging (CMSA) procedure \cite[]{prive2019efficient}.
We also introduce a second parameter, \texttt{power\_adaptive}, which can be used to put less penalizition on variants with the largest marginal effects \cite[]{zou2006adaptive}; we try 3 values here (0 the default, 0.5 and 1.5) and the best one is chosen within the CMSA procedure.

\subsection*{LDpred2-auto}

Using the individual-level data from the training set in the UK biobank, we run a linear regression GWAS using function \texttt{big\_univLinReg} of R package bigstatsr \cite[]{prive2017efficient}, accounting for the same covariates as in the penalized regression above.
As LD reference, we use the one provided in \cite{prive2020ldpred2} for European ancestry.
We use these summary statistics and this LD reference as input for LDpred2-auto.
LDpred2 assumes a point-normal mixture distribution for effect sizes, where only a proportion of causal variants $p$ contributes to the heritability $h^2$.
In LDpred2-auto, these two parameters are directly estimated from the data \cite[]{prive2020ldpred2}.
We use the \texttt{sparse} option in LDpred2-auto to also obtain a vector of effects that is potentially sparse, i.e.\ effects of some variants are exactly 0.
Also note that, as we use linear regression for all phenotypes, we use the total sample size instead of the effective sample size ($4/\left(1 / n_\text{case} + 1 / n_\text{control}\right)$) for binary phenotypes as input to LDpred2.
This means that heritability estimates from both LD score regression and LDpred2-auto has to be transformed to the liability scale using both the prevalence in the GWAS and in the population; this can be performed using function \texttt{coef\_to\_liab} from R package bigsnpr.
For simplicity, we assume here that the prevalence in the population is the same as the prevalence in the training set.

[ADD SOMETHING ABOUT HOW TO CHOOSE CHAINS?]

\subsection*{New formula used in LDpred2}

We also slightly modify the formula used in \cite{prive2020ldpred2}; we have previously used
\[\left(\text{se}(\hat{\gamma}_j)\right)^2 = \dfrac{(\boldsymbol{\breve{y}} - \hat{\gamma}_j \boldsymbol{\breve{G}_j})^T (\boldsymbol{\breve{y}} - \hat{\gamma}_j \boldsymbol{\breve{G}_j})}{(n - K - 1) ~ \boldsymbol{\breve{G}_j}^T \boldsymbol{\breve{G}_j}} \approx \dfrac{\boldsymbol{\breve{y}}^T \boldsymbol{\breve{y}}}{n ~ \boldsymbol{\breve{G}_j}^T \boldsymbol{\breve{G}_j}} \approx \dfrac{\text{var}(\boldsymbol{y})}{n ~ \text{var}(\boldsymbol{G_j})} ~,\]
where $\hat{\gamma}_j$ is the marginal effect of variant $j$, and where $\boldsymbol{\breve{y}}$ and $\boldsymbol{\breve{G}_j}$ are the vectors of phenotypes and genotypes for variant $j$ residualized from $K$ covariates, e.g.\ centering them.
The first approximation expects $\hat{\gamma}_j$ to be small, while the second approximation assumes the effects from covariates are small.
However, we found here that some variants can have very large effects, e.g.\ one variant explains about 30\% of the variance in bilirubin log-concentration.
Then, instead we compute \[(\boldsymbol{\breve{y}} - \hat{\gamma}_j \boldsymbol{\breve{G}_j})^T (\boldsymbol{\breve{y}} - \hat{\gamma}_j \boldsymbol{\breve{G}_j}) =
\boldsymbol{\breve{y}}^T \boldsymbol{\breve{y}}
- 2 \hat{\gamma}_j \boldsymbol{\breve{G}_j}^T \boldsymbol{\breve{y}}
+ \hat{\gamma}_j^2 \boldsymbol{\breve{G}_j}^T \boldsymbol{\breve{G}_j} =
\boldsymbol{\breve{y}}^T \boldsymbol{\breve{y}}
- \hat{\gamma}_j^2 \boldsymbol{\breve{G}_j}^T \boldsymbol{\breve{G}_j} ~,\]
which now gives (note the added term $\hat{\gamma}_j^2$)
\begin{equation}\label{eq:approx-sd-lin}
\text{sd}(\boldsymbol{G_j}) \approx \dfrac{\text{sd}(\boldsymbol{\breve{y}})}{\sqrt{n ~ \text{se}(\hat{\gamma}_j)^2 + \hat{\gamma}_j^2}} ~.
\end{equation}
Figure \ref{fig:new-formula} shows that the updated formula \eqref{eq:approx-sd-lin} is better; we now use it in the code of LDpred2, and also recommend using it for the QC procedure proposed in \cite{prive2020ldpred2}.

\subsection*{Using more than HapMap3 variants in LDpred2}

Here we also run LDpred2 using more than HapMap3 variants, based on a set of 8M+ variants (see above).
However, LDpred2 cannot be run on 8M variants because it is quadratic with the number of variants in terms of time and memory requirements.
Thus, we employ another strategy consisting in keeping only the 1M most significant variants.
To correct for winner's curse, we employ the maximum likelihood estimator used in \cite{zhong2008bias} and \cite{shi2016winner}:
\[Z = Z^* + \dfrac{\phi\left(Z^* - Z_{thr}\right) - \phi\left(-Z^* - Z_{thr}\right)}{\Phi\left(Z^* - Z_{thr}\right) + \Phi\left(-Z^* - Z_{thr}\right)} ~,\]
where $\phi$ is the standard normal density function, $\Phi$ is the standard normal cumulative density function, $Z$ is the Z-score obtained from the GWAS, $Z_{thr}$ is the threshold used on (absolute) Z-scores for filtering, and $Z^*$ is the corrected Z-score that we estimate and use.
As input for LDpred2, instead of using $\beta$ (along with $\text{SE}(\beta)$ and $N$), we use $\beta^* = \beta \cdot Z^* / Z$ where $Z = \beta / \text{SE}(\beta)$.
This is now implemented in function \texttt{snp\_thr\_correct} of package bigsnpr.

\subsection*{Performance metric}

Here we use the partial correlation as the performance metric, which is the correlation between the PGS and the phenotype after they have been both residualized using the covariates used in this paper (i.e.\ sex, age, birth date, deprivation index and 16 PCs).
To derive 95\% confidence intervals for these correlations, we use Fisher's Z-transformation.
We implement this in function \texttt{pcor} of R package bigstatsr and use it here.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\clearpage
%\vspace*{5em}

\section*{Software and code availability}

All code used for this paper is available at \url{https://github.com/privefl/UKBB-PGS/tree/master/code}. Links to the code used for the two supplementary notes are provided there.
We have extensively used R packages bigstatsr and bigsnpr \cite[]{prive2017efficient} for analyzing large genetic data, packages from the future framework \cite[]{bengtsson2020unifying} for easy scheduling and parallelization of analyses on the HPC cluster, and packages from the tidyverse suite \cite[]{wickham2019welcome} for shaping and visualizing results.
We have also used R package deming to fit Deming regressions.

R packages bigstatsr and bigsnpr can be installed from GitHub and CRAN.
A tutorial on fitting penalized regressions with R package bigstatsr is available at \url{https://privefl.github.io/bigstatsr/articles/penalized-regressions.html}.
A tutorial on running LDpred2 with R package bigsnpr is available at \url{https://privefl.github.io/bigsnpr/articles/LDpred2.html}.

\section*{Acknowledgements}

Authors thank GenomeDK and Aarhus University for providing computational resources and support that contributed to these research results.
This research has been conducted using the UK Biobank Resource under Application Number 58024.

\section*{Funding}

F.P. and B.V.\ are supported by the Danish National Research Foundation (Niels Bohr Professorship to Prof. John McGrath), and also acknowledge the Lundbeck Foundation Initiative for Integrative Psychiatric Research, iPSYCH (R248-2017-2003).

\section*{Declaration of Interests}

The authors declare no competing interests.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\bibliographystyle{natbib}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
